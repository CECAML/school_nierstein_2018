{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not forget to swapoff -a\n",
    "import numpy as np       # linear algebra\n",
    "import pylab as pl       # plots\n",
    "import tensorflow as tf  # just for data sets (no deep learning yet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((60000, 28, 28), (60000,))\n",
      "((10000, 28, 28), (10000,))\n"
     ]
    }
   ],
   "source": [
    "# choose wisely\n",
    "(train, label_train), (test, label_test) = tf.keras.datasets.mnist.load_data()\n",
    "#(train, label_train), (test, label_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "# make sure your data is floating point\n",
    "test = test.astype(np.float32)\n",
    "train = train.astype(np.float32)\n",
    "\n",
    "# print shapes\n",
    "print(train.shape, label_train.shape)\n",
    "print(test.shape, label_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((60000, 28, 28), (60000,))\n",
      "((10000, 28, 28), (10000,))\n"
     ]
    }
   ],
   "source": [
    "# here we can subsample in the data set\n",
    "num_test, num_train = 10000, 60000\n",
    "test, label_test = test[:num_test], label_test[:num_test]\n",
    "train, label_train = train[:num_train], label_train[:num_train]\n",
    "\n",
    "# print shapes\n",
    "print(train.shape, label_train.shape)\n",
    "print(test.shape, label_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_one_hot(labels, depths):\n",
    "    \n",
    "    result = np.zeros((labels.shape[0], depths))\n",
    "    \n",
    "    for index, label in enumerate(labels):\n",
    "        result[index, label] = 1\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "label_train_1 = to_one_hot(label_train, 10)\n",
    "label_test_1 = to_one_hot(label_test, 10)\n",
    "\n",
    "print(label_train_1.shape)\n",
    "print(label_test_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reinterpret R^{28 x 28} as R^{784}\n",
    "train, test = train.reshape((-1, 784)), test.reshape((-1, 784))\n",
    "\n",
    "# homogeneous embedding Ax + a <=> (A, a) (x) = (A x + a)\n",
    "#                                  (0, 1) (1)   (   1   )\n",
    "train_h = np.hstack((train, np.ones((train.shape[0], 1))))\n",
    "test_h  = np.hstack((test, np.ones((test.shape[0], 1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(785, 10)\n"
     ]
    }
   ],
   "source": [
    "# X A = Y   (m, 784+1) (785, 10) = (m, 10)\n",
    "# obviously, we have to find X^+ such that X^+ X = id\n",
    "A = np.linalg.pinv(train_h).dot(label_train_1)\n",
    "\n",
    "print(A.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_train = train_h.dot(A)\n",
    "predicted_test  = test_h.dot(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8577333333333333\n",
      "0.8603\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(predicted_train.argmax(axis=1) == label_train))\n",
    "print(np.mean(predicted_test.argmax(axis=1) == label_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(train, label_train, test, label_test):\n",
    "    \"\"\" train*A = label_train \"\"\"\n",
    "    \n",
    "    A = np.linalg.pinv(train).dot(label_train)\n",
    "  \n",
    "    predicted_train = train.dot(A)\n",
    "    predicted_test  = test.dot(A)\n",
    "       \n",
    "    return (np.mean(predicted_train.argmax(axis=1) == label_train.argmax(axis=1)),\n",
    "            np.mean(predicted_test.argmax(axis=1)  == label_test.argmax(axis=1)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(244, (1.0, 0.5634))\n",
      "(353, (1.0, 0.4867))\n",
      "(510, (1.0, 0.2364))\n",
      "(736, (1.0, 0.4848))\n",
      "(1062, (0.9971751412429378, 0.6493))\n",
      "(1532, (0.9771540469973891, 0.7096))\n",
      "(2211, (0.952962460425147, 0.7694))\n",
      "(3191, (0.9272955186461924, 0.7999))\n",
      "(4605, (0.9129207383279044, 0.8242))\n",
      "(6645, (0.8991723100075244, 0.832))\n",
      "(9589, (0.8819480654917092, 0.8354))\n",
      "(13837, (0.8746115487461155, 0.8461))\n",
      "(19968, (0.8664863782051282, 0.8529))\n",
      "(28814, (0.8629832720205456, 0.8565))\n",
      "(41579, (0.8593761273719907, 0.8603))\n",
      "(60000, (0.8577333333333333, 0.8603))\n"
     ]
    }
   ],
   "source": [
    "for m in np.logspace(0.5, 1.0, num=16, base=train_h.shape[0]).astype(np.int64):\n",
    "    print(m, fit(train_h[:m], label_train_1[:m], test_h, label_test_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient descent\n",
    "# L(A) = ||XA-Y||_F^2\n",
    "# @L/@A = 2 Xt (XA-Y)\n",
    "\n",
    "def fit(train, label_train, test, label_test, \n",
    "        num_iterations=2**16, alpha=1E-7, batch_size=32):\n",
    "    \n",
    "    A = np.zeros((train.shape[1], label_train.shape[1])) # (784+1, 10)\n",
    "       \n",
    "    for iteration in range(num_iterations):\n",
    "        indices = np.random.choice(train.shape[0], batch_size, replace=False)\n",
    "        \n",
    "        X = train[indices]       # (m, 784+1)\n",
    "        Y = label_train[indices] # (m, 10)\n",
    "    \n",
    "        G  = X.T.dot(X.dot(A)-Y)/(batch_size)\n",
    "        A -= alpha*G\n",
    "      \n",
    "    predicted_train = train.dot(A)\n",
    "    predicted_test  = test.dot(A)\n",
    "       \n",
    "    return (np.mean(predicted_train.argmax(axis=1) == label_train.argmax(axis=1)),\n",
    "            np.mean(predicted_test.argmax(axis=1)  == label_test.argmax(axis=1)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(244, (1.0, 0.6089))\n",
      "(353, (1.0, 0.6526))\n",
      "(510, (1.0, 0.6834))\n",
      "(736, (0.998641304347826, 0.7181))\n",
      "(1062, (0.9868173258003766, 0.7518))\n",
      "(1532, (0.9484334203655352, 0.7774))\n",
      "(2211, (0.9262777023971054, 0.8037))\n",
      "(3191, (0.902851770604826, 0.8162))\n",
      "(4605, (0.8964169381107492, 0.8208))\n",
      "(6645, (0.8823175319789315, 0.8312))\n",
      "(9589, (0.8673480029200125, 0.8341))\n",
      "(13837, (0.861241598612416, 0.8406))\n",
      "(19968, (0.8608774038461539, 0.8526))\n",
      "(28814, (0.8574304157701117, 0.8555))\n"
     ]
    }
   ],
   "source": [
    "for m in np.logspace(0.5, 1.0, num=16, base=train_h.shape[0]).astype(np.int64):    \n",
    "    print(m, fit(train_h[:m], label_train_1[:m], test_h, label_test_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
